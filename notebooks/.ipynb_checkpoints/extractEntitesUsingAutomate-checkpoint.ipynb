{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.ouseful.info/2017/09/04/simple-text-analysis-using-python-identifying-named-entities-tagging-fuzzy-string-matching-and-topic-modelling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting pyahocorasick\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/07/59ea29342500c6e6d64e4bd95e8d48c89db2fce6dd9c6434e00608990eab/pyahocorasick-1.1.13.1.tar.gz (82kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 2.4MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyahocorasick\n",
      "  Running setup.py install for pyahocorasick ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed pyahocorasick-1.1.13.1\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyahocorasick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '''us_cities_states_counties.csv'''\n",
    "\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    csv_rows = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeCount = len(csv_rows)\n",
    "#placeCount = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityCount = 0\n",
    "cities = []\n",
    "\n",
    "while cityCount < placeCount:\n",
    "    for row in csv_rows[cityCount]:\n",
    "        place = row.split('|')\n",
    "        #print(place)\n",
    "        city = place[0]\n",
    "        cityCount +=1\n",
    "        \n",
    "        cities.append(city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wanakena',\n",
       " 'West Somerset',\n",
       " 'Metamora',\n",
       " 'Gracewood',\n",
       " 'Methow',\n",
       " 'New Hampshire',\n",
       " 'Drifton',\n",
       " 'Buckhead',\n",
       " 'Molino',\n",
       " 'Cuttingsville']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = list(set(cities))\n",
    "cities[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_search = cities[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = '''The town was founded in 1902 by cousins Herbert and Horace Rich, founders of the Rich Brothers Lumber Company. Rich Lumber purchased 16,000 acres (65 km2) on the southwestern shore of Cranberry Lake, and constructed several mills to work the lumber. Housing for the millworkers was built in part from lumber salvaged from the company's abandoned Pennsylvania lumber operation with many of these homes still in existence. At the height of lumbering & milling activities in Wanakena (1902-1912) there were up to 1500 workers at the Rich Brothers mill and associated industries. Prior to leaving the deforested area, Rich Lumber Company donated land to Syracuse University to start the first school in the nation to educate forest rangers and to encourage sustainable forestry practices with the first school built in 1912. The Environmental School of Forestry is now part of SUNY and is the oldest Ranger School / School of Forestry in the country.\n",
    "\n",
    "A logging railroad was constructed connecting Wanakena to the Carthage and Adirondack Railroad at Benson Mines, starting operation in 1905. After the lumber insustry left the area, the rails were dismantled because of a significant decrease in people traveling to and from Wanakena.\n",
    "\n",
    "A suspension footbridge built over the Active Directory Oswegatchie River before 1903 connected the hamlet and the mills for company workers and was one of the longest suspension foot bridges in the United State. The footbridge had been listed on the National Register of Historic Places prior to being destroyed by an ice jam on January 14, 2014. Community efforts began immediately to rebuild the bridge with over $130,000 raised as of May 2016. Several grants and donations by local Foundations were used with the donated money for a matching grant from the New York State Office of Parks, Recreation and Historic Places. Reconstruction of the bridge was completed in November 2016. The Wanakena Presbyterian Church is also listed on the National Register of Historic Places.\n",
    "\n",
    "The Wanakena Historical 'Analytics Entity Extraction Association developed a historical walking tour (2002) that includes two kiosks and six picture stations that display historical pictures and narratives on the history of the hamlet, logging, milling, railroad, and tourism. The walking tour is visited annually by schools, bus tours and tourists. The walking tour is free and open to the public from May 30 to at least Labor Day.\n",
    "\n",
    "Today there still is a vibrant community in this Active Directory little pioneer village on the Oswegatchie River. In addition to the SUNY ESF school, The church has weekly services during the summer (9:15am), post-office, Otto's Abode, the Otto J Hamele Historic Walking Tour, gazebo where weekly summer concerts are held, and the Pine Cone Grill on Ranger School Road.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2753"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ahocorasick\n",
    "\n",
    "A = ahocorasick.Automaton()\n",
    "\n",
    "for idx, key in enumerate(list_to_search):\n",
    "    A.add_word(key, (idx, key))\n",
    "\n",
    "    A.make_automaton()\n",
    "    \n",
    "def test_ac(A, text):\n",
    "    entries = []\n",
    "    for entry in A.iter(text):\n",
    "        entries.append(entry)\n",
    "\n",
    "    return entries\n",
    "    \n",
    "def test_list(list_to_search, text):\n",
    "    entries = []\n",
    "    for entry in list_to_search:\n",
    "        if entry in text:\n",
    "            entries.append(entry)\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 µs ± 3.88 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit test_ac(A, article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ahocorasick import Automaton\n",
    "\n",
    "A=Automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2='Boris Johnson went off to Europe to complain about the European Union'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.add_word(\"Europe\",(('VOCAB', len(\"Europe\")),'Europe'))\n",
    "A.add_word(\"European Union\",(('VOCAB', len(\"European Union\")),'European Union'))\n",
    "A.add_word(\"Boris Johnson\",(('PERSON', len(\"Boris Johnson\")),'Boris Johnson'))\n",
    "A.add_word(\"Boris\",(('PERSON', len(\"Boris\")),'Boris Johnson'))\n",
    "\n",
    "A.add_word(\"Active Directory\",(('CV_FEATURE', len(\"Active Directory\")),'Active Directory'))\n",
    "\n",
    " \n",
    "A.make_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Active Directory', 'Analytics Entity Extraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in features:\n",
    "    #print(i)\n",
    "    A.add_word(str(i),(('CV_FEATURE', len(\"Active Directory\")),'Active Directory'))\n",
    "    A.make_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.add_word(\"Active Directory\",(('CV_FEATURE', len(\"Active Directory\")),'Active Directory'))\n",
    "A.make_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1286, (('CV_FEATURE', 16), 'Active Directory')) he *Active Directory* Os\n",
      "(2063, (('CV_FEATURE', 16), 'Active Directory')) s E*ntity Extraction* As\n",
      "(2510, (('CV_FEATURE', 16), 'Active Directory')) is *Active Directory* li\n"
     ]
    }
   ],
   "source": [
    "for item in A.iter(article):\n",
    "    start=item[0]-item[1][0][1]+1\n",
    "    end=item[0]+1\n",
    "    print(item, '{}*{}*{}'.format(article[start-3:start],article[start:end],article[end:end+3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNote = '''I have the confirmation of customer to assist to Commvault Go and also the partner is registered. \n",
    "Agustin and I expect to negotiate and close the project as last year there. This will be a 40TB growth, \n",
    "but the discount is really high because is a 10 years EMC store, we are growing snap snap restore and the only way i this account \n",
    "to growth will be based on price and in procurement.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ahocorasick import Automaton\n",
    "\n",
    "A=Automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have the confirmation of customer to assist to commvault go and also the partner is registered. \\nagustin and i expect to negotiate and close the project as last year there. this will be a 40tb growth, \\nbut the discount is really high because is a 10 years emc store, we are growing and the only way i this account \\nto growth will be based on price and in procurement.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testNote.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['active directory', 'edge drive plug-in for kapost', 'explorer plug-in', 'outlook add-in', 'outlook add-in with contentstore email viewer', 'outlook add-in with contentstore and edge attachment store', 'sql management studio plug-in', 'system center', 'vrealize plug-in', 'vsphere plug-in', 'additional settings', 'alert', 'alert console alerts', 'alert email', 'alert rss', 'alert scom', 'alert snmp', 'alert windows event', 'alert workflow integration', 'analytics', 'analytics entity extraction', 'analytics lucidworks fusion integration', 'analytics web analytics', 'app studio', 'app studio app builder', 'app studio custom report builder', 'app studio workflow', 'application aware backups', 'archiving', 'onepass', 'ad-hoc backup and archiving.', 'cross platform stub restores', 'days based retention', 'disk cleanup', 're-stubbing', 'redundancy', 'restore as data', 'stub pruning', 'stub recovery', 'stub filters', 'audit trail', 'auto discover database/instance', 'automation', 'auxiliary copy', 'copy selected job', 'dash copy', 'inline copies', 'parallel copies', 'reof secondary copy', 'selective copy', 'spool copy', 'support for global tape copy across storage policies', 'backups', 'data protection', 'backup external link', 'backup offline data', 'block level', 'config files backup', 'data only backup', 'enterprise backup using sbt', 'entire instance', 'exclusive backup', 'fast incremental', 'forever incremenal backup with trueup', 'hana studio', 'image backupset', 'media parameters', 'multistream', 'optimized scan', 'partial backup', 'persistent log backup', 'proxy backup', 'proxy media agent', 'replication and standby', 'third party command line backup', 'three way backup', 'tiered file storage using reference copy', 'two way backup', 'volume level backup', 'whole instance', 'backward compatibility', 'big data', 'cassandra', 'distributed backup', 'gpfs', 'gpfs automatic clustered monitoring across cluster or client nodes', 'gpfs disk cleanup', 'gpfs native snap', 'glusterfs', 'glusterfs optimized scan', 'greenplum', 'hadoop', 'hadoop hdfs migration from on-prem to cloud and vice versa', 'hadoop non-hadoop data restore to hadoop', 'lustre', 'branding', 'browse protected data', 'browse protected data find', 'browse protected data live browse', 'browse protected data live machine and unc browse/download/upload', 'browse protected data view and restore versions', 'business logic workflow', 'client configuration', 'client group', 'client group automatic client group', 'clone policies', 'cloud applications', 'amazon rds & ebs', 'amazon s3', 'azure blob', 'ceph s3', 'google drive /mail', 'one drive', 'salesforce', 'cloud database migration', 'migration to amazon cloud', 'migration to oracle ebs app', 'migration to oraclecloud', 'cloud services', 'commcell registration', 'health report', 'system discovery', 'upgrade testing in cloud', 'cluster', 'commcell migration', 'cloud grc', 'cross commcell restores', 'grc', 'media explorer', 'tape import', 'commserver', 'commserver disaster recovery', 'commserver dr to commvault cloud', 'commserver dr to external cloud', 'commserver live sync', 'commserver less backup', 'commserver commserver - linux', 'console interfaces', 'admin console', 'command line', 'java console', 'mobile console', 'python sdk', 'rest api', 'user preferences', 'web console', 'content indexing', 'continous data replication', 'discrete replication', 'corporate event & survey management', 'custom calendar', 'db2', 'db2 dpf', 'db2 hadr', 'db2 offline backup', 'db2 online subset', 'dblayer', 'data aging', 'extended retention', 'extending selective job retention', 'data loss prevention', 'gridstore', 'automatic restore from any copy', 'geo location', 'load balancing', 'pairing client and mediaagent for data protection and restore', 'restore from anywhere', 'data transportx', 'data integrity validation', 'data integrity validation media crc', 'data integrity validation network crc', 'pipeline', 'sdt(simple data transfer)', 'data verification', 'datacube', 'datacube connectors csv', 'datacube connectors eloqua', 'datacube connectors federated search', 'datacube connectors http', 'datacube connectors ldap', 'datacube connectors open data sources', 'datacube connectors twitter', 'datacube connectors websites', 'database archiving', 'database archiving native, xml and parquet', 'deduplication', 'client side deduplication', 'ddb backups', 'ddb move', 'ddb partition support', 'ddb reconstruction', 'ddb verification', 'dash full', 'disk defragmentation and compaction', 'global policy', 'resync', 'silo', 'store priming', 'transaction database', 'variable content alignment', 'dev-test & dr orchestration', 'dev-test & dr orchestration failover groups', 'documentation', 'bol content', 'help content', 'documentumx', 'fti as the indexing server', 'xplore as the indexing server', 'full text index backups', 'oracle backup', 'storage area backups', 'drivers', 'email / smtp configuration', 'encryption', 'application password v5 encryption', 'commvault key management', 'encryption hardware', 'key management', 'privacy', 'third party key management', 'events', 'exchange', 'database', 'mailbox', 'mailbox (classic)', 'mailbox (classic) onepass', 'mailbox delegation', 'mailbox imap access', 'mailbox migration apis', 'mailbox pst archiving', 'mailbox public folders', 'mailbox recall mailbox', 'mailbox reply/forward', 'mailbox retention tags/quota', 'mailbox smtp gateway', 'mailbox snap mining', 'online(0365)', 'external data connector', 'data connector migration', 'file systemx', 'fs extent level', 'long path support', 'm time based backups', 'optimized hard link backup', 'system state support', 'filters', 'foundation', 'gdpr', 'gdpr emails', 'gdpr files', 'gdpr other applications', 'geolocation', 'hardware refresh', 'hardware refresh application', 'hardware refresh commserv', 'hardware refresh disk library', 'hardware refresh disk library automatic storage detection', 'hardware refresh disk library hardware single instancing support', 'hardware refresh disk library spanning across disks', 'hardware refresh mediaagent', 'hardware support', 'hardware support hba', 'hardware support hpe catalyst', 'hardware support tape drive', 'hardware support tape library', 'hardware support vtl', 'healthcare applications', 'healthcare applications clinical archiving', 'healthcare applications clinical archiving clinical viewer', 'healthcare applications clinical archiving dicom', 'healthcare applications epic her', 'healthcare applications intersystem cache', 'healthcare applications meditech', 'ibm i-series', 'ibm i-series vtl backup', 'indexing', 'indexing catalog migration', 'indexing delete data', 'indexing index backup', 'indexing index cleanup', 'indexing index compaction', 'indexing list media', 'informix', 'infrastructure tools', 'infrastructure tools cvlegal', 'infrastructure tools engweb', 'infrastructure tools projectplan', 'infrastructure tools recut center', 'infrastructure tools snap center', 'infrastructure tools update center', 'install/upgrade', 'install/upgrade custom package', 'install/upgrade decoupled install', 'install/upgrade native package install', 'install/upgrade remote install/upgrade', 'install/upgrade silent install', 'job management', 'activity control', 'control panel options', 'job controller', 'job history', 'operation window', 'operation window holiday', 'restartibility', 'job results', 'laptop', 'laptop backup monitor tool', 'laptop client commserver database (ccsdb)', 'laptop cloud direct', 'laptop collaborative shares', 'laptop comments', 'laptop device/user migration', 'laptop edge drive', 'laptop file activity notification', 'laptop file download', 'laptop file edit using wopi', 'laptop file previews', 'laptop file upload', 'laptop laptop sync', 'laptop mac tags', 'laptop migration assistant', 'laptop photos application native browse', 'laptop prescan', 'laptop share from web console', 'laptop tags', 'laptop uploader tools', 'laptop user centric & device centric backup', 'laptop user profile discovery and enumeration', 'laptop web edit tool', 'licensing', 'licensing billing', 'licensing cloud licensing', 'licensing multi-tier licensing', 'licensing private licensing server', 'live mount', 'live mount recovery point manager', 'live mount recovery point manager offline browse', 'live sync', 'live sync live sync direct', 'live sync live sync io', 'localization', 'log file', 'log file gxadmin', 'log file log streaming to cloud', 'log file sendlog', 'log file view log', 'lotus notes', 'lotus notes archiver', 'lotus notes database', 'lotus notes doc', 'lotus notes migration to 0365', 'msp', 'msp backup quotas and limits', 'msp companies', 'msp download center', 'machine learning', 'machine learning file activity anomaly detection', 'machine learning job run time anomaly detection', 'machine learning job success/failure anomaly detection', 'media management', 'media management centera library', 'media management cloud - glacier/cold storage', 'media management cloud storage', 'media management cloud storage cloud library seeding using snowball and other hardware', 'media management cloud storage disk to cloud conversion', 'media management disk library protection against external writes', 'media management multiplexing', 'media management removeable storage support', 'media management removeable storage support plug n play disk', 'media management removeable storage support rdx drive/media', 'media management snaplock', 'media management tape library sharing across commcell', 'media management tapedrive/library', 'media management tapedrive/library automatic device detection/configuration', 'media management tapedrive/library automatic drive replacement', 'media management tapedrive/library backup spanning across tapes', 'media management tapedrive/library barcode pattern', 'media management tapedrive/library drive pooling', 'media management tapedrive/library dual hba support', 'media management tapedrive/library erase media', 'media management tapedrive/library library sharing across commcell', 'media management tapedrive/library multipathing support', 'media management tapedrive/library refresh media', 'media management tapedrive/library standalone drive support', 'media management tapedrive/library support for scsi3 reservations', 'media management tapedrive/library vtl support', 'media management tapedrive/library worm media', 'media management vault tracker', 'mongodb', 'mysql', 'nas', 'nas nas auditing', 'nas nas ndmp', 'nas nas ndmp dar/non dar', 'nas nas ndmp multi node backups', 'nas nas ndmp multi stream backups', 'nas nas ndmp supported vendors', 'name change', 'network', 'network share/cifs/nfs', 'network share/cifs/nfs filer retirement', 'network certificates', 'network data interface pair', 'network firewall configuration and network topologies', 'network internet gateway', 'network network throttling', 'network tppm', 'network vpn', 'object store', 'object store/content store interfaces', 'object store/content store interfaces cdmi', 'object store/content store interfaces callback filesystem(cbfs)', 'object store/content store interfaces ftp', 'object store/content store interfaces hl7', 'object store/content store interfaces jive', 'object store/content store interfaces kapost', 'object store/content store interfaces nfs/cifs', 'object store/content store interfaces nfs/cifs netezza backup and restore', 'object store/content store interfaces nfs/cifs teradata backup/restore', 'object store/content store interfaces netsuite', 'object store/content store interfaces rest', 'object store/content store interfaces s3', 'object store/content store interfaces webdav', 'object store/content store interfaces xds', 'object store/content store interfaces iscsi', 'office 365', 'office 365 office 365 migration', 'openvms', 'openvms os volume and system recovery', 'openvms pre-post scripts', 'openstack swift', 'oracle', 'oracle cloud storage', 'oracle rac', 'oracle agent less backup', 'oracle online backup', '', 'postgresql', 'power management', 'records manager', 'reports', 'reports classic report', 'reports classic report client readiness', 'reports explorer views', 'reports metrics', 'reports metrics report activity', 'reports metrics report chargeback', 'reports metrics report dashboard in cloud', 'reports metrics report forwarding/tiered metrics', 'reports metrics report growth and trends', 'reports metrics report health report', 'reports metrics report license usage', 'reports metrics report managed services advanced reporting', 'reports metrics report peak capacity report', 'reports metrics report profile', 'reports metrics report rpo/rto', 'reports metrics report sla', 'reports metrics report scrubbing', 'reports metrics report user management', 'reports report store', 'reports web console reports', 'reports web console reports exports', 'reports web console reports job summary', 'reports web console reports power point and document generation from cloud', 'restores', 'data recovery', 'restores 1-touch (bmr)', 'restores cross server', 'restores cross machine restore', 'restores cross tenant database restore', 'restores data only restore', 'restores database copy', 'restores database archived redo logs', 'restores dockerize me', 'restores duplicate, cross restore', 'restores hypervisor convert', 'restores in place', 'restores map file restore', 'restores multi-stream restore', 'restores out of place', 'restores partial restore', 'restores recurring restore', 'restores table level', 'restores virtualize me', 'sap archivelink', 'sap archivelink sap migration utility', 'sap flexframe', 'sap hana', 'sap maxdb', 'sap oracle', 'sap oracle archive log backup', 'sap oracle brtools command line backups', 'sap oracle consistent online backups', 'sap oracle selective online full backup', 'sap oracle standby database backups', 'solr', 'sql', 'sql azure/aws', 'sql sql always on', 'sql sql on linux', 'scalability', 'scalability performance & resource utilization', 'scalability resource manager', 'scalability work queue', 'schedule & schedule policy', 'schedule & schedule policy automatic schedule', 'schedule & schedule policy continous schedule', 'security', 'security domains & organizaiton', 'security identity management', 'security roles', 'security user & user groups', 'security websecurity', 'service now', 'service now backup/recovery', 'service now integration with alerting and ticketing', 'services', 'services process manager', 'services web services', 'services web services tomcat services', 'sharepoint', 'sharepoint database', 'sharepoint document', 'sharepoint farm', 'sharepoint sharepoint rbs', 'sharepoint sharepoint rbs file connector', 'sharepoint site collection', 'snap', 'intellisnap', 'snap array configuration', 'snap array controller', 'snap backup copy', 'snap clone', 'snap connection protocols', 'snap deferred catalog', 'snap hardware replication', 'snap metro high availability configurations', 'snap netapp spos,nosb', 'snap netapp snapmanagement tool', 'snap proxy clients', 'snap remotesnap ma', 'snap replication', 'snap replication using netapps ocum server', 'snap revert', 'snap skip catalog and live browse', 'snap snap engines', 'snap snap restore', 'snap snap restore redirect restore', 'snap unc shares multi-node mount support', 'snap vsa proxyless mount', 'software compression', 'software store', 'software store automatic client group rules', 'software store custom alerts', 'software store gdpr reports', 'software store media kits', 'software store premium reports', 'software store quick access tools', 'software store workflows', 'space check', 'splunk', 'storage policy', 'storage pools', 'storage pools dataserver fc', 'storage pools dataserver hyper-scale', 'storage pools dataserver ip', 'storage provisioning', 'storage provisioning provisioning policy', 'storage replication', 'subclient policy', 'sybase', 'synthetic full', 'system monitoring', 'system monitoring file monitoring', 'system monitoring log monitoring', 'system monitoring log monitoring log management backup', 'system monitoring resource monitoring', 'time and time zone', 'logs', 'troubleshooting (jpr, events, logs,bol)', 'kb articles', 'pro-active support', 'remote troubleshooting', 'updates', 'updates cloud upgrade testing', 'updates hotfix packs', 'updates hotfix updates', 'updates service packs', 'virtualization', 'virtualization alicloud', 'virtualization amazon', 'virtualization appaware', 'virtualization azure', 'virtualization azure stack', 'virtualization changed block tracking', 'virtualization docker', 'virtualization file level recovery', 'virtualization fusioncompute', 'virtualization google cloud', 'virtualization hyperv', 'virtualization kubernetes', 'virtualization nutanix ahv', 'virtualization openstack', 'virtualization oraclecloud', 'virtualization oraclevm', 'virtualization provisioning', 'virtualization rhev', 'virtualization vddk', 'virtualization vmware', 'virtualization vmware vmc', 'virtualization vmware vcloud', 'virtualization vmware vsan', 'virtualization vmware vvol', 'virtualization xenserver', 'e-discovery', 'e-discovery case manager', 'e-discovery globanet integration', 'e-discovery reference copy', 'e-discovery sms archiving']\n"
     ]
    }
   ],
   "source": [
    "with open(\"cv_feature.txt\", 'r') as f:\n",
    "    cvfeature = []\n",
    "    for i in f.readlines():\n",
    "        cvfeature.append(str(i).replace('\\n', '').lower())\n",
    "    print(cvfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cvfeature:\n",
    "    #print(i)\n",
    "    A.add_word(str(i),(('CV_FEATURE', len(str(i))),str(i)))\n",
    "    A.make_automaton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, (('CV_FEATURE', 4), 'snap')) ng *snap* sn\n",
      "found features: snap\n",
      "(292, (('CV_FEATURE', 4), 'snap')) ap *snap* re\n",
      "found features: snap\n",
      "(300, (('CV_FEATURE', 17), 'snap snap restore')) ng *snap snap restore* an\n",
      "found features: snap snap restore\n"
     ]
    }
   ],
   "source": [
    "for item in A.iter(testNote):\n",
    "    start=item[0]-item[1][0][1]+1\n",
    "    end=item[0]+1\n",
    "    print(item, '{}*{}*{}'.format(testNote[start-3:start],testNote[start:end],testNote[end:end+3]))\n",
    "    print('found features: {}'.format(testNote[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
